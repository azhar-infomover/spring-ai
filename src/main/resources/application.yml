server:
  port: ${PORT:8080}

spring:
  application:
    name: spring-ai
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: deepseek-r1:1.5b #llama2 or mistral, depending on your preference
    #          temperature: 0.7
    mistralai:
      api-key: ${MISTRAL_AI_API_KEY}
      chat:
        options:
          model: mixtral-8x7b
          temperature: 0.7
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-3.5-turbo
          temperature: 0.7

gemini:
  api-key: ${GEMINI_API_KEY}
  api-endpoint: ${GEMINI_API_ENDPOINT:https://generativelanguage.googleapis.com/v1beta/models}
